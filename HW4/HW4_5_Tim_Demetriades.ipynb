{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4\n",
    "## Tim Demetriades\n",
    "### AAI 695 WS2 - Shucheng Yu\n",
    "4/6/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 - Programming\n",
    "#### In this programming problem, you will get familiar with building a neural network using backpropagation. You are supposed to implement the following steps: \n",
    "#### Step 1: Use our “titanic” dataset in homework #3, and split data in the same way you did in homework #3 – 80% as training and 20% test sets; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv(\"Titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.337494</td>\n",
       "      <td>B5</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.550003</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.550003</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Crei</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.550003</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessi</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.550003</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 pclass  survived                             name     sex  \\\n",
       "0           1    1st         1    Allen, Miss. Elisabeth Walton  female   \n",
       "1           2    1st         1   Allison, Master. Hudson Trevor    male   \n",
       "2           3    1st         0     Allison, Miss. Helen Loraine  female   \n",
       "3           4    1st         0  Allison, Mr. Hudson Joshua Crei    male   \n",
       "4           5    1st         0  Allison, Mrs. Hudson J C (Bessi  female   \n",
       "\n",
       "       age  sibsp  parch  ticket        fare    cabin     embarked boat  \\\n",
       "0  29.0000      0      0   24160  211.337494       B5  Southampton    2   \n",
       "1   0.9167      1      2  113781  151.550003  C22 C26  Southampton   11   \n",
       "2   2.0000      1      2  113781  151.550003  C22 C26  Southampton  NaN   \n",
       "3  30.0000      1      2  113781  151.550003  C22 C26  Southampton  NaN   \n",
       "4  25.0000      1      2  113781  151.550003  C22 C26  Southampton  NaN   \n",
       "\n",
       "    body                        home.dest  \n",
       "0    NaN                     St Louis, MO  \n",
       "1    NaN  Montreal, PQ / Chesterville, ON  \n",
       "2    NaN  Montreal, PQ / Chesterville, ON  \n",
       "3  135.0  Montreal, PQ / Chesterville, ON  \n",
       "4    NaN  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  1309 non-null   int64  \n",
      " 1   pclass      1309 non-null   object \n",
      " 2   survived    1309 non-null   int64  \n",
      " 3   name        1309 non-null   object \n",
      " 4   sex         1309 non-null   object \n",
      " 5   age         1046 non-null   float64\n",
      " 6   sibsp       1309 non-null   int64  \n",
      " 7   parch       1309 non-null   int64  \n",
      " 8   ticket      1309 non-null   object \n",
      " 9   fare        1308 non-null   float64\n",
      " 10  cabin       295 non-null    object \n",
      " 11  embarked    1307 non-null   object \n",
      " 12  boat        486 non-null    object \n",
      " 13  body        121 non-null    float64\n",
      " 14  home.dest   745 non-null    object \n",
      "dtypes: float64(3), int64(4), object(8)\n",
      "memory usage: 153.5+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1308.000000</td>\n",
       "      <td>121.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.381971</td>\n",
       "      <td>29.881135</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>33.295479</td>\n",
       "      <td>160.809917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>378.020061</td>\n",
       "      <td>0.486055</td>\n",
       "      <td>14.413500</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>51.758669</td>\n",
       "      <td>97.696922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>328.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>982.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329224</td>\n",
       "      <td>328.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     survived          age        sibsp        parch  \\\n",
       "count  1309.000000  1309.000000  1046.000000  1309.000000  1309.000000   \n",
       "mean    655.000000     0.381971    29.881135     0.498854     0.385027   \n",
       "std     378.020061     0.486055    14.413500     1.041658     0.865560   \n",
       "min       1.000000     0.000000     0.166700     0.000000     0.000000   \n",
       "25%     328.000000     0.000000    21.000000     0.000000     0.000000   \n",
       "50%     655.000000     0.000000    28.000000     0.000000     0.000000   \n",
       "75%     982.000000     1.000000    39.000000     1.000000     0.000000   \n",
       "max    1309.000000     1.000000    80.000000     8.000000     9.000000   \n",
       "\n",
       "              fare        body  \n",
       "count  1308.000000  121.000000  \n",
       "mean     33.295479  160.809917  \n",
       "std      51.758669   97.696922  \n",
       "min       0.000000    1.000000  \n",
       "25%       7.895800   72.000000  \n",
       "50%      14.454200  155.000000  \n",
       "75%      31.275000  256.000000  \n",
       "max     512.329224  328.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will turn the age and fare from categorical to numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_age = titanic_df.age.mean()\n",
    "average_fare = titanic_df.fare.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.age.fillna(average_age, inplace = True)\n",
    "titanic_df.fare.fillna(average_fare, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we replace these strings for the pclass column with integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1st', '2nd', '3rd'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.pclass.unique()    # show all ticket classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_dict = {'1st': 1, '2nd': 2, '3rd': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.pclass.replace(pclass_dict, inplace = True)    # replace strings with ints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we replace male with 0 and female with 1 and then split the set into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dict = {'male': 0, 'female': 1}    # male = 0, female = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.sex.replace(sex_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where the full dataset is split into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(titanic_df,  test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Fit a neural network using independent variables ‘pclass + sex + age + sibsp’ and  dependent variable ‘survived’. Fill in n/a attributes with the average of the same attributes from other training examples. Use 2 hidden layers and set the activation functions for both the hidden and output layer to be the sigmoid function. Set “solver” parameter as either SGD (stochastic gradient descend) or Adam (similar to SGD but optimized performance with mini batches). You can adjust parameter “alpha” for regularization (to control overfitting) and other parameters such as “learning rate” and “momentum” as needed.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the features and labels are split for the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[['pclass', 'sex', 'age', 'sibsp']]\n",
    "X_test = test_df[['pclass', 'sex', 'age', 'sibsp']]\n",
    "y_train = train_df['survived']\n",
    "y_test = test_df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.881135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.881135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1047 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  sex        age  sibsp\n",
       "772        3    0  17.000000      0\n",
       "543        2    0  36.000000      0\n",
       "289        1    1  18.000000      0\n",
       "10         1    0  47.000000      1\n",
       "147        1    0  29.881135      0\n",
       "...      ...  ...        ...    ...\n",
       "1095       3    1  29.881135      0\n",
       "1130       3    1  18.000000      0\n",
       "1294       3    0  28.500000      0\n",
       "860        3    1  26.000000      0\n",
       "1126       3    1  28.000000      0\n",
       "\n",
       "[1047 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.881135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.881135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.881135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  sex        age  sibsp\n",
       "1148       3    0  35.000000      0\n",
       "1049       3    0  20.000000      1\n",
       "982        3    0  29.881135      0\n",
       "808        3    0  29.881135      0\n",
       "1195       3    0  29.881135      0\n",
       "...      ...  ...        ...    ...\n",
       "572        2    1  28.000000      0\n",
       "140        1    0  23.000000      0\n",
       "1182       3    1  21.000000      0\n",
       "312        1    0  50.000000      1\n",
       "199        1    1  24.000000      0\n",
       "\n",
       "[262 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Multi-layer Perceptron is sensitive to feature scaling, we should standardize features by removing the mean and scaling to unit variance.\n",
    "\n",
    "Formula: `z = (x - u) / s`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)    # only fit to training data\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.84035898, -0.73927586, -0.98672562, -0.4959643 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.84035898, -0.73927586,  0.42270133, -0.4959643 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a MLP Classifier is created and fit to the training data.\n",
    "\n",
    "It uses the **adam solver**, a **learning rate of 0.0001**, the **logistic (sigmoid) activation function**, and **2 hidden layers with 4 neurons each**. These hyperparameters were chosen based on some minor testing to see which gave the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timjr\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(4, 4), random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MLPClassifier(solver = 'adam', \n",
    "                           alpha = 0.0001,\n",
    "                           activation = 'logistic',    # sigmoid\n",
    "                           random_state = 42,\n",
    "                           hidden_layer_sizes = (4, 4))    # two hidden layers with 4 neurons each\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can use the `.score()` method to see the mean accuracy on the training and test data to get a general idea of how well the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061127029608405"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_train, y_train)    # mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7709923664122137"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)    # mean accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Check the performance of the model with out-of-sample accuracy, defined as:\n",
    "#### - out-of-sample percent survivors correctly predicted (on test set)  \n",
    "#### - out-of-sample percent fatalities correctly predicted (on test set)\n",
    "#### Please try two different network structures (i.e., number of neurons at each hidden layer) and show their respective accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the predictions for both the training and test data are obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = classifier.predict(X_train)\n",
    "predict_test = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the predictions a confusion matrix and classification report can be created. The confusion matrix is then used to calculate the accuracy for both the number of survivors and number of fatalities correctly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[595  70]\n",
      " [133 249]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       665\n",
      "           1       0.78      0.65      0.71       382\n",
      "\n",
      "    accuracy                           0.81      1047\n",
      "   macro avg       0.80      0.77      0.78      1047\n",
      "weighted avg       0.80      0.81      0.80      1047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tn_train, fp_train, fn_train, tp_train = confusion_matrix(y_train, predict_train).ravel()\n",
    "print(confusion_matrix(y_train, predict_train))\n",
    "print(classification_report(y_train, predict_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[129  15]\n",
      " [ 45  73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.90      0.81       144\n",
      "           1       0.83      0.62      0.71       118\n",
      "\n",
      "    accuracy                           0.77       262\n",
      "   macro avg       0.79      0.76      0.76       262\n",
      "weighted avg       0.78      0.77      0.77       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, predict_test).ravel()\n",
    "print(confusion_matrix(y_test,predict_test))\n",
    "print(classification_report(y_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Survivors Correctly Predicted: 61.86%\n"
     ]
    }
   ],
   "source": [
    "survivors_accuracy = tp_test / (tp_test + fn_test)\n",
    "print(f'Percent Survivors Correctly Predicted: {survivors_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Fatalities Correctly Predicted: 89.58%\n"
     ]
    }
   ],
   "source": [
    "fatalities_accuracy = tn_test / (tn_test + fp_test)\n",
    "print(f'Percent Fatalities Correctly Predicted: {fatalities_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, this network correctly predicts around **62% of survivors and around 90% of fatalities** (which match the recall values for the test data classification report).\n",
    "\n",
    "While the fatality accuracy is pretty high, the survivor accuracy is still pretty low. Let's see if we can improve this with a different network structure.\n",
    "\n",
    "First let's try to **increase the number of neurons in both of the two hidden layers to 8**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timjr\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(8, 8), random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_2 = MLPClassifier(solver = 'adam', \n",
    "                             alpha = 0.0001,\n",
    "                             activation = 'logistic',    # sigmoid\n",
    "                             random_state = 42,\n",
    "                             hidden_layer_sizes = (8, 8))    # two hidden layers with 8 neurons each\n",
    "classifier_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8089780324737345"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_2.score(X_train, y_train)    # mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7442748091603053"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_2.score(X_test, y_test)    # mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = classifier_2.predict(X_train)\n",
    "predict_test = classifier_2.predict(X_test)\n",
    "tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, predict_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Survivors Correctly Predicted: 51.69%\n"
     ]
    }
   ],
   "source": [
    "survivors_accuracy = tp_test / (tp_test + fn_test)\n",
    "print(f'Percent Survivors Correctly Predicted: {survivors_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Fatalities Correctly Predicted: 93.06%\n"
     ]
    }
   ],
   "source": [
    "fatalities_accuracy = tn_test / (tn_test + fp_test)\n",
    "print(f'Percent Fatalities Correctly Predicted: {fatalities_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The survivor accuracy has decreased dramatically to around 52% while the fatality accuracy has increased to around 93%**.\n",
    "\n",
    "Let's try one more network structure. This time, **we will bring the number of neurons down from 8 to 6** (still higher than the original number of neurons of 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timjr\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(6, 6), random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_3 = MLPClassifier(solver = 'adam', \n",
    "                             alpha = 0.0001,\n",
    "                             activation = 'logistic',    # sigmoid\n",
    "                             random_state = 42,\n",
    "                             hidden_layer_sizes = (6, 6))    # two hidden layers with 4 neurons each\n",
    "classifier_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8042024832855779"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_3.score(X_train, y_train)    # mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7748091603053435"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_3.score(X_test, y_test)    # mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = classifier_3.predict(X_train)\n",
    "predict_test = classifier_3.predict(X_test)\n",
    "tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, predict_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Survivors Correctly Predicted: 62.71%\n"
     ]
    }
   ],
   "source": [
    "survivors_accuracy = tp_test / (tp_test + fn_test)\n",
    "print(f'Percent Survivors Correctly Predicted: {survivors_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Fatalities Correctly Predicted: 89.58%\n"
     ]
    }
   ],
   "source": [
    "fatalities_accuracy = tn_test / (tn_test + fp_test)\n",
    "print(f'Percent Fatalities Correctly Predicted: {fatalities_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the **survivor accuracy is now around 63%**, which is slightly higher than when using 4 neurons in the two hidden layers, and the **fatality accuracy is around 90%**, the same as with 4 neurons.\n",
    "\n",
    "This network seems to give the best results. Of note, the weight optimizer (solver) used is **adam**, which gave better results than **sgd** (not shown). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Compare the out-of-sample accuracy (as defined in step 3) with the random forest obtained in homework #3. (You can either use a table or plot the results of the two algorithms in one figure). Explain any difference in accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Random Forest in HW2\n",
    "rf_survivors_accuracy = 0.5000\n",
    "rf_fatalities_accuracy = 0.9583"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [['Neural Network'],\n",
    "         ['Survivor Accuracy', 'Fatality Accuracy'],\n",
    "         [f'{survivors_accuracy:.2%}', f'{fatalities_accuracy:.2%}'],\n",
    "         [''],\n",
    "         ['Random Forest'],\n",
    "         ['Survivor Accuracy', 'Fatality Accuracy'],\n",
    "         [f'{rf_survivors_accuracy:.2%}', f'{rf_fatalities_accuracy:.2%}']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------  -----------------\n",
      "Neural Network\n",
      "Survivor Accuracy  Fatality Accuracy\n",
      "62.71%             89.58%\n",
      "\n",
      "Random Forest\n",
      "Survivor Accuracy  Fatality Accuracy\n",
      "50.00%             95.83%\n",
      "-----------------  -----------------\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table shows the survivor and fatality accuracy for both the Random Forest model created for HW3 and the Neural Network model created for this HW.\n",
    "\n",
    "As can be seen, while the fatality accuracy has gone down by around 6%, the survivor accuracy has increased by over 12% for the Neural Network. As a result we can say that this model performed better than the Random Forest model.\n",
    "\n",
    "It is not always clear from the start which model will perform better for a given problem, which is why it is important to try different models and compare the results. This is essentially what was done here, with the Random Forest and Neural Network models both producing different results. From what we found, the Neural Network model seems to perform slightly better.\n",
    "\n",
    "Generally, Neural Networks are more complex than Random Forests and therefore if they produce similar results than it will be better to just go with a Random Forest. Random Forests can do a great job at classifying binary data, which is what we have here. Neural Networks can also work for binary classification, but tend to need more data. Also, with Neural Networks, it can be difficult to explain why they make the decisions they make ('black box') compared to with Random Forests.\n",
    "\n",
    "However, as seen here, the Neural Network performed better than the Random Forest given the dataset, particularly with the configured hyperparameters (solver, numebr of hidden layers, number of neurons)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
